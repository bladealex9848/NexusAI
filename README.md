# NexusAI

Un motor de b√∫squeda potenciado por IA con una interfaz de usuario generativa, impulsado por MALLO (MultiAgent LLM Orchestrator).

![captura](/public/capture-240404_blk.png)

> [!NOTA]
> Por favor, ten en cuenta que pueden existir diferencias entre este repositorio y el sitio web oficial [nexusai.com](https://nexusai.com). El sitio web oficial es una bifurcaci√≥n de este repositorio con caracter√≠sticas adicionales como autenticaci√≥n, necesarias para proporcionar el servicio en l√≠nea. El c√≥digo fuente principal de NexusAI reside en este repositorio y est√° dise√±ado para ser f√°cilmente construido y desplegado.

## üóÇÔ∏è Visi√≥n General

- üõ† [Caracter√≠sticas](#-caracter√≠sticas)
- üß± [Stack Tecnol√≥gico](#-stack-tecnol√≥gico)
- üöÄ [Inicio R√°pido](#-inicio-r√°pido)
- üåê [Despliegue](#-despliegue)
- üîé [Motor de B√∫squeda](#-motor-de-b√∫squeda)
- ‚úÖ [Modelos Verificados](#-modelos-verificados)
- ü§ñ [Estructura de MALLO](#-estructura-de-mallo)

## üõ† Caracter√≠sticas

- B√∫squeda y respuesta utilizando Interfaz de Usuario Generativa
- Comprensi√≥n avanzada de las preguntas del usuario
- Funcionalidad de historial de b√∫squedas
- Compartir resultados de b√∫squeda
- Soporte para b√∫squeda de videos
- Obtener respuestas de URLs espec√≠ficas
- Usar como motor de b√∫squeda predeterminado
- Soporte para m√∫ltiples proveedores de IA:
  - OpenAI
  - Google Generative AI
  - Azure OpenAI
  - Anthropic
  - Ollama
  - Groq
  - Together AI
  - DeepInfra
  - DeepSeek
  - Mistral AI
  - Cohere
- Especificar el modelo para generar respuestas
- Soporte para Redis local y en la nube (Upstash)
- Soporte para API de b√∫squeda SearXNG con profundidad personalizable
- Profundidad de b√∫squeda configurable (b√°sica o avanzada)
- Integraci√≥n con MALLO para razonamiento avanzado y orquestaci√≥n de m√∫ltiples agentes de IA

## üß± Stack Tecnol√≥gico

- Framework de aplicaci√≥n: [Next.js](https://nextjs.org/)
- Streaming de texto / UI Generativa: [Vercel AI SDK](https://sdk.vercel.ai/docs)
- Modelo Generativo Principal: [MALLO (MultiAgent LLM Orchestrator)](https://github.com/bladealex9848/MALLO)
- API de B√∫squeda: [Tavily AI](https://tavily.com/) / [Serper](https://serper.dev) / [SearXNG](https://docs.searxng.org/)
- API de Lectura: [Jina AI](https://jina.ai/)
- Base de Datos (Serverless/Local): [Upstash](https://upstash.com/) / [Redis](https://redis.io/)
- Biblioteca de componentes: [shadcn/ui](https://ui.shadcn.com/)
- Primitivas de componentes sin cabeza: [Radix UI](https://www.radix-ui.com/)
- Estilos: [Tailwind CSS](https://tailwindcss.com/)

## üöÄ Inicio R√°pido

### 1. Bifurcar y Clonar el repositorio

Bifurca el repositorio a tu cuenta de Github, luego ejecuta el siguiente comando para clonar el repo:

```
git clone git@github.com:bladealex9848/NexusAI.git
```

### 2. Instalar dependencias

```
cd NexusAI
bun install
```

### 3. Configurar Upstash Redis

Sigue la gu√≠a para configurar Upstash Redis. Crea una base de datos y obt√©n `UPSTASH_REDIS_REST_URL` y `UPSTASH_REDIS_REST_TOKEN`. Consulta la [gu√≠a de Upstash](https://upstash.com/docs/redis/overall/getstarted) para obtener instrucciones detalladas.

Si planeas usar Redis local, puedes omitir este paso.

### 4. Completar los secretos

```
cp .env.local.example .env.local
```

Edita el archivo `.env.local` con tus claves API y configuraciones.

### 5. Ejecutar la aplicaci√≥n localmente

#### Usando Bun

```
bun dev
```

#### Usando Docker

```
docker compose up -d
```

Visita http://localhost:3000 en tu navegador web.

## üåê Despliegue

Aloja tu propia versi√≥n en vivo de NexusAI con Vercel o Cloudflare Pages.

### Vercel

[![Desplegar con Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Fbladealex9848%2FNexusAI&env=OPENAI_API_KEY,TAVILY_API_KEY,UPSTASH_REDIS_REST_URL,UPSTASH_REDIS_REST_TOKEN)

## üîé Motor de B√∫squeda

### Configurar NexusAI como Motor de B√∫squeda en tu Navegador

1. Abre la configuraci√≥n de tu navegador.
2. Navega a la secci√≥n de configuraci√≥n del motor de b√∫squeda.
3. A√±ade un nuevo motor de b√∫squeda con la siguiente URL:
   `https://nexusai.com/search?q=%s`
4. Establece NexusAI como tu motor de b√∫squeda predeterminado.

### Usar SearXNG como Backend de B√∫squeda Alternativo

NexusAI soporta SearXNG como backend de b√∫squeda alternativo. Consulta la secci√≥n de configuraci√≥n en el archivo `config.yaml` para m√°s detalles sobre c√≥mo configurar y personalizar SearXNG.

## ‚úÖ Modelos Verificados

NexusAI, potenciado por MALLO, soporta una amplia gama de modelos de lenguaje. Aqu√≠ se presenta una lista de los modelos verificados y compatibles:

### Modelos Generales

- OpenAI
  - GPT-4
  - GPT-4 Turbo
  - GPT-3.5 Turbo
- Google
  - Gemini Pro
  - Gemini Ultra (cuando est√© disponible)
- Anthropic
  - Claude 2
  - Claude 3 (Opus, Sonnet, Haiku)
- Cohere
  - Command
  - Command-R
- Mistral AI
  - Mistral 7B
  - Mixtral 8x7B
- Ollama (modelos locales)
  - Llama 2
  - Mistral
  - Phi-2
- Groq
  - LLaMA 2 70B
  - Mixtral 8x7B
- Together AI
  - Varios modelos de c√≥digo abierto
- DeepInfra
  - Soporte para m√∫ltiples modelos de diferentes proveedores

### Modelos Especializados

- Modelos de visi√≥n (multimodales)
  - GPT-4 Vision
  - Gemini Pro Vision
  - Claude 3 (con capacidades de visi√≥n)
- Modelos de c√≥digo
  - OpenAI Codex
  - Anthropic Claude (optimizado para tareas de codificaci√≥n)
  - GitHub Copilot (integraci√≥n)

### Modelos de Embeddings

- OpenAI Ada
- Cohere Embed
- Mistral Embed

### Modelos de Voz y Audio

- Whisper (OpenAI)
- Google Speech-to-Text

Esta lista se actualiza regularmente a medida que se verifican y a√±aden nuevos modelos al ecosistema de NexusAI y MALLO.

## ü§ñ Estructura de MALLO

MALLO (MultiAgent LLM Orchestrator) es el n√∫cleo de NexusAI y proporciona las siguientes capacidades:

- Orquestaci√≥n din√°mica de m√∫ltiples modelos de lenguaje
- Evaluaci√≥n de complejidad de consultas
- Sistema de cach√© para respuestas frecuentes
- Integraci√≥n con APIs de b√∫squeda web
- Manejo de contexto y seguimiento de conversaciones
- Selecci√≥n inteligente de agentes basada en el tipo de consulta
- Capacidad de expansi√≥n para nuevos modelos y proveedores

Para m√°s detalles sobre la estructura y funcionamiento de MALLO, consulta la [documentaci√≥n de MALLO](https://github.com/bladealex9848/MALLO).

## üìö Documentaci√≥n

Para obtener informaci√≥n m√°s detallada sobre la configuraci√≥n, uso y personalizaci√≥n de NexusAI, consulta nuestra [documentaci√≥n completa](https://docs.nexusai.com).

## ü§ù Contribuci√≥n

Las contribuciones son bienvenidas. Por favor, lee nuestra [gu√≠a de contribuci√≥n](CONTRIBUTING.md) antes de enviar pull requests.

## üìÑ Licencia

Este proyecto est√° licenciado bajo la Licencia MIT. Consulta el archivo [LICENSE](LICENSE) para m√°s detalles.

## üìû Contacto

Para soporte o consultas, por favor abre un issue en este repositorio o contacta con nuestro equipo en info@marduk.pro.

---

Desarrollado con ‚ù§Ô∏è por el equipo de [Marduk](https://marduk.pro)
